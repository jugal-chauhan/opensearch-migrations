apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: cluster-templates
spec:
  serviceAccountName: argo-workflow-executor
  
  templates:
    # Elasticsearch 5.6 Single Node Template
    - name: elasticsearch-5-6-single-node
      inputs:
        parameters:
          - name: cluster-name
          - name: namespace
      container:
        image: dtzar/helm-kubectl:latest
        command: [sh, -c]
        args:
          - |
            # Add Elasticsearch Helm repository
            helm repo add elastic https://helm.elastic.co
            helm repo update
            
            # Create Elasticsearch configuration for ES 5.6.16
            cat > /tmp/elasticsearch.yml << EOF
            bootstrap.system_call_filter: false
            network.host: 0.0.0.0
            cloud.aws.access_key: test
            cloud.aws.secret_key: test
            cloud.aws.region: us-east-2
            discovery.zen.minimum_master_nodes: 1
            EOF
            
            # Create Helm values file for ES 5.6.16
            cat > /tmp/es-values.yaml << 'EOF'
            fullnameOverride: {{inputs.parameters.cluster-name}}
            image: "docker.elastic.co/elasticsearch/elasticsearch"
            imageTag: "5.6.16"
            antiAffinity: "soft"
            esJavaOpts: "-Xmx512m -Xms512m"
            protocol: "http"
            replicas: 1
            createCert: false
            clusterHealthCheckParams: "wait_for_status=yellow&timeout=3s"
            readinessProbe:
              failureThreshold: 5
              successThreshold: 2
            extraEnvs:
              - name: "cluster.initial_master_nodes"
                value: ""
              - name: "node.roles"
                value: ""
            persistence:
              enabled: false
            
            extraInitContainers:
              - name: install-s3-plugin
                image: docker.elastic.co/elasticsearch/elasticsearch:5.6.16
                command: ["sh", "-c", "bin/elasticsearch-plugin install --batch repository-s3"]
                volumeMounts:
                  - name: plugins
                    mountPath: /usr/share/elasticsearch/plugins
            
            extraVolumes:
              - name: plugins
                emptyDir: {}
            
            extraVolumeMounts:
              - name: plugins
                mountPath: /usr/share/elasticsearch/plugins
            EOF
            
            # Install Elasticsearch 5.6.16
            helm install {{inputs.parameters.cluster-name}} elastic/elasticsearch \
              --version 8.5.1 \
              --namespace {{inputs.parameters.namespace}} \
              --values /tmp/es-values.yaml \
              --set-file esConfig."elasticsearch\.yml"=/tmp/elasticsearch.yml
            
            # Generate cluster configuration output
            cat > /tmp/cluster-config.json << EOF
            {
              "endpoint": "http://{{inputs.parameters.cluster-name}}:9200",
              "allow_insecure": true,
              "no_auth": null,
              "version": "ES_5.6"
            }
            EOF

            kubectl create configmap {{inputs.parameters.cluster-name}}-migration-config \
              --from-file=cluster-config=/tmp/cluster-config.json \
              --namespace {{inputs.parameters.namespace}}
            
            echo "Elasticsearch 5.6.16 cluster"
            echo "Cluster config:"
            cat /tmp/cluster-config.json
      outputs:
        parameters:
          - name: cluster-config
            valueFrom:
              path: /tmp/cluster-config.json

    # Elasticsearch 7.10 Single Node Template
    - name: elasticsearch-7-10-single-node
      inputs:
        parameters:
          - name: cluster-name
          - name: namespace
      container:
        image: dtzar/helm-kubectl:latest
        command: [sh, -c]
        args:
          - |
            # Add Elasticsearch Helm repository
            helm repo add elastic https://helm.elastic.co
            helm repo update
            
            cat > /tmp/elasticsearch.yml << EOF
            network.host: 0.0.0.0
            discovery.type: single-node
            EOF
            
            cat > /tmp/es-values.yaml << 'EOF'
            fullnameOverride: {{inputs.parameters.cluster-name}}
            image: "docker.elastic.co/elasticsearch/elasticsearch-oss"
            imageTag: "7.10.2"
            antiAffinity: "soft"
            esJavaOpts: "-Xmx512m -Xms512m"
            protocol: "http"
            replicas: 1
            createCert: false
            clusterHealthCheckParams: "wait_for_status=yellow&timeout=3s"
            readinessProbe:
              failureThreshold: 5
              successThreshold: 2
            extraEnvs:
              - name: node.roles
                value: "master,data,ingest"
              - name: "cluster.initial_master_nodes"
                value: ""
              - name: "AWS_REGION"
                value: "us-east-2"
            
              
            persistence:
              enabled: false
            
            extraInitContainers:
              - name: install-s3-plugin
                image: docker.elastic.co/elasticsearch/elasticsearch-oss:7.10.2
                command: ["sh", "-c", "bin/elasticsearch-plugin install --batch repository-s3"]
                volumeMounts:
                  - name: plugins
                    mountPath: /usr/share/elasticsearch/plugins
              - name: inject-aws-creds
                image: docker.elastic.co/elasticsearch/elasticsearch-oss:7.10.2
                command:
                  - sh
                  - -c
                  - |
                    set -e
                    echo "Creating Elasticsearch keystore and adding AWS credentials"
                    bin/elasticsearch-keystore create -f
                    echo "test" | bin/elasticsearch-keystore add --stdin s3.client.default.access_key --force
                    echo "test" | bin/elasticsearch-keystore add --stdin s3.client.default.secret_key --force
                    chown 1000:0 /usr/share/elasticsearch/config/elasticsearch.keystore
                    chmod 600 /usr/share/elasticsearch/config/elasticsearch.keystore
                    # Copy keystore to shared volume location
                    cp /usr/share/elasticsearch/config/elasticsearch.keystore /shared/elasticsearch.keystore
                    echo "Keystore created and saved to shared volume"
                volumeMounts:
                  - name: elasticsearch-keystore
                    mountPath: /shared
                    
            
            extraVolumes:
              - name: plugins
                emptyDir: {}
              - name: elasticsearch-keystore
                emptyDir: {}
            
            extraVolumeMounts:
              - name: plugins
                mountPath: /usr/share/elasticsearch/plugins
              - name: elasticsearch-keystore
                mountPath: /usr/share/elasticsearch/config/elasticsearch.keystore
                subPath: elasticsearch.keystore
            EOF
            
            helm install {{inputs.parameters.cluster-name}} elastic/elasticsearch \
              --version 8.5.1 \
              --namespace {{inputs.parameters.namespace}} \
              --values /tmp/es-values.yaml \
              --set-file esConfig."elasticsearch\.yml"=/tmp/elasticsearch.yml
            
            # Generate cluster configuration output
            cat > /tmp/cluster-config.json << EOF
            {
              "endpoint": "http://{{inputs.parameters.cluster-name}}:9200",
              "allow_insecure": true,
              "no_auth": null,
              "version": "ES_7.10"
            }
            EOF

            kubectl create configmap {{inputs.parameters.cluster-name}}-migration-config \
              --from-file=cluster-config=/tmp/cluster-config.json \
              --namespace {{inputs.parameters.namespace}}
            
            echo "Elasticsearch 7.10 cluster"
            echo "Cluster config:"
            cat /tmp/cluster-config.json
      outputs:
        parameters:
          - name: cluster-config
            valueFrom:
              path: /tmp/cluster-config.json

    # Elasticsearch 8.18 Single Node Template
    - name: elasticsearch-8-18-single-node
      inputs:
        parameters:
          - name: cluster-name
          - name: namespace
      container:
        image: bitnamisecure/kubectl:latest
        command: [sh, -c]
        args:
          - |
            set -eu
            
            NS="{{inputs.parameters.namespace}}"
            NAME="{{inputs.parameters.cluster-name}}"
            ECK_NS="elastic-system"
            ECK_VER="2.15.0"
            
            # Ensure target namespace exists
            kubectl get ns "${NS}" >/dev/null 2>&1 || kubectl create ns "${NS}"
            
            # --- Ensure ECK operator (CRDs + deployment) is installed (idempotent) ---
            if ! kubectl get crd elasticsearches.elasticsearch.k8s.elastic.co >/dev/null 2>&1; then
              echo "[ECK] Installing CRDs ${ECK_VER}…"
              kubectl apply -f "https://download.elastic.co/downloads/eck/${ECK_VER}/crds.yaml"
              
              # Wait for key CRDs to be Established
              kubectl wait --for=condition=Established --timeout=120s \
                crd/elasticsearches.elasticsearch.k8s.elastic.co \
                crd/kibanas.kibana.k8s.elastic.co \
                crd/enterprisesearches.app.k8s.elastic.co || true
            fi
    
            # Ensure operator namespace exists
            kubectl get ns "${ECK_NS}" >/dev/null 2>&1 || kubectl create ns "${ECK_NS}"
    
            # Install/upgrade operator (safe if already present)
            echo "[ECK] Installing/upgrading operator ${ECK_VER}…"
            kubectl apply -f "https://download.elastic.co/downloads/eck/${ECK_VER}/operator.yaml"
    
            # Wait for operator to be available
            kubectl rollout status deploy/elastic-operator -n "${ECK_NS}" --timeout=300s
    
            # Optional: wait for webhook registration (helps avoid admission races)
            for i in $(seq 1 60); do
              if kubectl get validatingwebhookconfiguration elastic-webhook.k8s.elastic.co >/dev/null 2>&1; then
                echo "[ECK] Webhook registered."
                break
              fi
              sleep 2
            done
            # --- ECK ready ---
            
            # Secret with S3 creds -> will be written into the keystore by ECK
            cat > /tmp/es-s3-credentials.yaml <<EOF
            apiVersion: v1
            kind: Secret
            metadata:
              name: ${NAME}-s3-credentials
              namespace: ${NS}
            type: Opaque
            stringData:
              s3.client.default.access_key: test
              s3.client.default.secret_key: test
            EOF
            
            # Elasticsearch CR
            cat > /tmp/es.yaml <<EOF
            apiVersion: elasticsearch.k8s.elastic.co/v1
            kind: Elasticsearch
            metadata:
              name: ${NAME}
              namespace: ${NS}
            spec:
              version: 8.18.4
              http:
                tls:
                  selfSignedCertificate:
                    disabled: true
              nodeSets:
              - name: default
                count: 1
                config:
                  xpack.security.enabled: false
                  xpack.security.enrollment.enabled: false
                  xpack.security.http.ssl.enabled: false
                  xpack.security.transport.ssl.enabled: false
                  xpack.ml.enabled: false
                  xpack.watcher.enabled: false
                  discovery.type: single-node
                  network.host: 0.0.0.0
                  node.max_local_storage_nodes: 1
            
                  # LocalStack S3 client config
                  s3.client.default.endpoint: http://localstack.${NS}.svc.cluster.local:4566
                  s3.client.default.path_style_access: true
                  s3.client.default.region: us-east-2
                
                secureSettings:
                  - secretName: ${NAME}-s3-credentials
                
                podTemplate:
                  spec:
                    containers:
                      - name: elasticsearch
                        env:
                          - name: ES_JAVA_OPTS
                            value: "-Xms512m -Xmx512m"
                          - name: "AWS_REGION"
                            value: "us-east-2"
                        volumeMounts:
                          - name: elasticsearch-data
                            mountPath: /usr/share/elasticsearch/data
                    volumes:
                      - name: elasticsearch-data
                        emptyDir: {}
                
                # Force ephemeral data: no PVCs
                volumeClaimTemplates: []
            EOF

            # Apply resources
            kubectl apply -f /tmp/es-s3-credentials.yaml
            kubectl apply -f /tmp/es.yaml
            
            # Wait for ECK to bring up the node
            # Try 'ready' condition first, fall back to check health via service
            SVC="${NAME}-es-http"
            # Wait for service to exist
            for i in $(seq 1 90); do
              if kubectl -n "${NS}" get svc "${SVC}" >/dev/null 2>&1; then break; fi
              sleep 2
            done
            
            # Wait for HTTP 200 on /
            for i in $(seq 1 120); do
              if kubectl -n "${NS}" run --rm -i --restart=Never tmp-curl-$$ --image=curlimages/curl:8.8.0 -- \
                -sS --max-time 2 "http://${SVC}.${NS}.svc:9200/" >/dev/null 2>&1; then
                break
              fi
              sleep 2
            done
            
            # Emit cluster-config.json
            cat > /tmp/cluster-config.json <<EOF
            {
              "endpoint": "http://${SVC}:9200",
              "allow_insecure": true,
              "no_auth": null,
              "version": "ES_8.18.4"
            }
            EOF

            kubectl create configmap ${NAME}-migration-config \
              --from-file=cluster-config=/tmp/cluster-config.json \
              --namespace ${NS} \
              --dry-run=client -o yaml | kubectl apply -f -
              
            echo "Elasticsearch ${NAME} ready at http://${SVC}:9200"
            echo "Cluster config:"
            cat /tmp/cluster-config.json
      outputs:
        parameters:
          - name: cluster-config
            valueFrom:
              path: /tmp/cluster-config.json

    # OpenSearch 1.3 Single Node Template
    - name: opensearch-1-3-single-node
      inputs:
        parameters:
          - name: cluster-name
          - name: namespace
      container:
        image: dtzar/helm-kubectl:latest
        command: [sh, -c]
        args:
          - |
            # Add OpenSearch Helm repository
            helm repo add opensearch https://opensearch-project.github.io/helm-charts/
            helm repo update
            
            # Create OpenSearch configuration
            cat > /tmp/opensearch.yml << EOF
            cluster.name: {{inputs.parameters.cluster-name}}
            network.host: 0.0.0.0
            discovery.type: single-node
            EOF
            
            # Create OpenSearch values file
            cat > /tmp/opensearch-values.yaml << 'EOF'
            fullnameOverride: {{inputs.parameters.cluster-name}}
            nodeGroup: ""
            image:
              repository: "opensearchproject/opensearch"
              tag: "1.3.20"
            singleNode: true
            replicas: 1
            resources:
              requests:
                cpu: "500m"
                memory: "1Gi"
              limits:
                cpu: "1000m"
                memory: "2Gi"
            persistence:
              enabled: false
            opensearchJavaOpts: "-Xmx1g -Xms1g"
            plugins:
              enabled: true
              installList:
                - "repository-s3"
            EOF
            
            # Install OpenSearch 1.3
            helm install {{inputs.parameters.cluster-name}} opensearch/opensearch \
              --namespace {{inputs.parameters.namespace}} \
              --values /tmp/opensearch-values.yaml \
              --set-file config."opensearch\.yml"=/tmp/opensearch.yml
            
            # Generate cluster configuration output
            cat > /tmp/cluster-config.json << EOF
            {
              "endpoint": "https://{{inputs.parameters.cluster-name}}:9200",
              "allow_insecure": true,
              "version": "OS_1.3",
              "basic_auth": {
                "username": "admin",
                "password": "admin"
              }
            }
            EOF

            kubectl create configmap {{inputs.parameters.cluster-name}}-migration-config \
              --from-file=cluster-config=/tmp/cluster-config.json \
              --namespace {{inputs.parameters.namespace}}
            
            echo "OpenSearch 1.3 cluster created successfully"
            echo "Cluster config:"
            cat /tmp/cluster-config.json
      outputs:
        parameters:
          - name: cluster-config
            valueFrom:
              path: /tmp/cluster-config.json

    # OpenSearch 2.19 Single Node Template
    - name: opensearch-2-19-single-node
      inputs:
        parameters:
          - name: cluster-name
          - name: namespace
      container:
        image: dtzar/helm-kubectl:latest
        command: [sh, -c]
        args:
          - |
            # Add OpenSearch Helm repository
            helm repo add opensearch https://opensearch-project.github.io/helm-charts/
            helm repo update
            
            # Create OpenSearch configuration
            cat > /tmp/opensearch.yml << EOF
            cluster.name: {{inputs.parameters.cluster-name}}
            network.host: 0.0.0.0
            discovery.type: single-node
            EOF
            
            # Create OpenSearch values file
            cat > /tmp/opensearch-values.yaml << 'EOF'
            fullnameOverride: {{inputs.parameters.cluster-name}}
            nodeGroup: ""
            image:
              repository: "opensearchproject/opensearch"
              tag: "2.19.1"
            singleNode: true
            replicas: 1
            extraEnvs:
              - name: "OPENSEARCH_INITIAL_ADMIN_PASSWORD"
                value: "myStrongPassword123!"
            resources:
              requests:
                cpu: "500m"
                memory: "1Gi"
              limits:
                cpu: "1000m"
                memory: "2Gi"
            persistence:
              enabled: false
            opensearchJavaOpts: "-Xmx1g -Xms1g"
            plugins:
              enabled: true
              installList:
                - "repository-s3"
            EOF
            
            # Install OpenSearch 2.19.1
            helm install {{inputs.parameters.cluster-name}} opensearch/opensearch \
              --namespace {{inputs.parameters.namespace}} \
              --values /tmp/opensearch-values.yaml \
              --set-file config."opensearch\.yml"=/tmp/opensearch.yml
            
            # Generate cluster configuration output
            cat > /tmp/cluster-config.json << EOF
            {
              "endpoint": "https://{{inputs.parameters.cluster-name}}:9200",
              "allow_insecure": true,
              "version": "OS_2.19",
              "basic_auth": {
                "username": "admin",
                "password": "myStrongPassword123!"
              }
            }
            EOF

            kubectl create configmap {{inputs.parameters.cluster-name}}-migration-config \
              --from-file=cluster-config=/tmp/cluster-config.json \
              --namespace {{inputs.parameters.namespace}}
            
            echo "OpenSearch 2.19.1 cluster created successfully"
            echo "Cluster config:"
            cat /tmp/cluster-config.json
      outputs:
        parameters:
          - name: cluster-config
            valueFrom:
              path: /tmp/cluster-config.json
