import argparse
import ast
from dataclasses import dataclass, field
import datetime
import os
import random
import re
import string
import subprocess
import sys
from typing import List, Optional, Tuple

from k8s_service import K8sService, HelmCommandFailed
from tabulate import tabulate
import logging

logging.basicConfig(format='%(asctime)s [%(levelname)s] %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

VALID_SOURCE_VERSIONS = ["ES_1.5", "ES_2.4", "ES_5.6", "ES_7.10"]
VALID_TARGET_VERSIONS = ["OS_1.3", "OS_2.19"]

# Version to template name mapping
VERSION_TO_TEMPLATE_MAP = {
    "ES_1.5": "elasticsearch-1-5-single-node",
    "ES_2.4": "elasticsearch-2-4-single-node",
    "ES_5.6": "elasticsearch-5-6-single-node",
    "ES_7.10": "elasticsearch-7-10-single-node",
    "OS_1.3": "opensearch-1-3-single-node",
    "OS_2.19": "opensearch-2-19-single-node"
}
MA_RELEASE_NAME = "ma"


# Data classes to represent test output generated by python e2e tests
@dataclass
class TestEntry:
    name: str
    description: str
    result: str
    duration: float
    error: Optional[str] = None


@dataclass
class TestSummary:
    passed: int
    failed: int
    source_version: str
    target_version: str


@dataclass
class TestReport:
    summary: TestSummary
    tests: List[TestEntry] = field(default_factory=list)


class TestsFailed(Exception):
    pass


class TestRunner:

    def __init__(self, k8s_service: K8sService, unique_id: str, test_ids: List[str],
                 ma_chart_path: str, combinations: List[Tuple[str, str]]) -> None:
        self.k8s_service = k8s_service
        self.unique_id = unique_id
        self.test_ids = test_ids
        self.ma_chart_path = ma_chart_path
        self.combinations = combinations

    def _print_test_stats(self, report: TestReport) -> None:
        for test in report.tests:
            print(f"{test.name}:")
            print(f"  - result: {test.result}")
            print(f"  - duration: {test.duration:.5f} seconds")
            if test.error:
                print(f"  - error: {test.error}")
            print()

    def _print_summary_table(self, reports: List[TestReport]) -> None:
        all_test_names = sorted({
            test.name for report in reports for test in report.tests
        })

        # Build the test matrix rows
        matrix_rows = []
        for report in reports:
            version_label = (
                f"{report.summary.source_version} -> {report.summary.target_version}"
            )
            row = [version_label]
            test_results = {
                test.name: "âœ“" if test.result == "passed" else "X"
                for test in report.tests
            }
            for name in all_test_names:
                row.append(test_results.get(name, ""))
            matrix_rows.append(row)

        # Build test description rows
        test_descriptions = {}
        for report in reports:
            for test in report.tests:
                test_descriptions.setdefault(test.name, test.description)

        # Print Test Matrix
        headers = ["Version"] + all_test_names
        print("\nTest Matrix:")
        print(tabulate(matrix_rows, headers=headers, tablefmt="fancy_grid"))

        # Print Test Case Information
        description_table = [
            [name, test_descriptions[name]] for name in all_test_names
        ]
        print("\nTest Case Information:")
        print(tabulate(
            description_table,
            headers=["Test Name", "Description"],
            tablefmt="fancy_grid"
        ))

        # Print Test Stats
        print("\nTest Stats:")
        for report in reports:
            version_pair = (
                f"{report.summary.source_version} -> {report.summary.target_version}"
            )
            print(f"===== {version_pair} =====")
            self._print_test_stats(report)

    def _parse_test_report(self, data: dict) -> TestReport:
        tests = [TestEntry(**test) for test in data.get("tests", [])]
        summary_data = data.get("summary", {})
        summary = TestSummary(
            passed=summary_data.get("passed", 0),
            failed=summary_data.get("failed", 0),
            source_version=summary_data.get("source_version", ""),
            target_version=summary_data.get("target_version", "")
        )
        return TestReport(tests=tests, summary=summary)

    def run_tests(self, source_version: str, target_version: str,
                  keep_workflows: bool = False, reuse_clusters: bool = False) -> bool:
        """Runs pytest tests."""
        logger.info(
            f"Executing migration test cases with pytest and test ID filters: {self.test_ids}"
        )
        command_list = [
            "pipenv",
            "run",
            "pytest",
            "/root/lib/integ_test/integ_test/ma_workflow_test.py",
            f"--unique_id={self.unique_id}",
            f"--source_version={source_version}",
            f"--target_version={target_version}"
        ]
        if self.test_ids:
            command_list.append(f"--test_ids={','.join(self.test_ids)}")
        if keep_workflows:
            command_list.append("--keep_workflows")
        if reuse_clusters:
            command_list.append("--reuse_clusters")
        command_list.append("-s")
        self.k8s_service.exec_migration_console_cmd(command_list=command_list)
        output_file_path = f"/root/lib/integ_test/results/{self.unique_id}/test_report.json"
        logger.info(f"Retrieving test report at {output_file_path}")
        cmd_response = self.k8s_service.exec_migration_console_cmd(
            command_list=["cat", output_file_path], unbuffered=False
        )
        test_data = ast.literal_eval(cmd_response)
        logger.debug(f"Received the following test data: {test_data}")
        test_report = self._parse_test_report(test_data)
        print(f"Test cases passed: {test_report.summary.passed}")
        print(f"Test cases failed: {test_report.summary.failed}")
        self._print_summary_table(reports=[test_report])
        if test_report.summary.passed == 0 or test_report.summary.failed > 0:
            return False
        return True

    def cleanup_clusters(self) -> None:
        pattern = re.compile(r"^(source|target)-(opensearch|elasticsearch)")
        for install in self.k8s_service.get_helm_installations():
            if pattern.match(install):
                self.k8s_service.helm_uninstall(release_name=install)
        for configmap in self.k8s_service.get_configmaps():
            if (pattern.match(configmap) and
                    configmap.endswith("migration-config")):
                self.k8s_service.delete_configmap(configmap_name=configmap)

    def cleanup_deployment(self) -> None:
        self.cleanup_clusters()
        self.k8s_service.helm_uninstall(release_name=MA_RELEASE_NAME)
        self.k8s_service.wait_for_all_healthy_pods()
        self.k8s_service.delete_all_pvcs()

    def copy_logs(self, destination: str = "./logs") -> None:
        self.k8s_service.copy_log_files(destination=destination)

    def run(self, skip_delete: bool = False, keep_workflows: bool = False,
            developer_mode: bool = False, reuse_clusters: bool = False) -> None:
        for source_version, target_version in self.combinations:
            try:
                logger.info(
                    f"Performing helm deployment for migration testing environment "
                    f"from {source_version} to {target_version}"
                )

                # Build chart values with template names based on versions
                chart_values = {}
                if developer_mode:
                    chart_values["developerModeEnabled"] = "true"
                
                # Map versions to template names
                source_template = VERSION_TO_TEMPLATE_MAP.get(source_version)
                target_template = VERSION_TO_TEMPLATE_MAP.get(target_version)
                
                if source_template:
                    chart_values[
                        "fullMigrationWithClusters.sourceClusterTemplate"
                    ] = source_template
                    logger.info(f"Setting source cluster template to: {source_template}")
                
                if target_template:
                    chart_values[
                        "fullMigrationWithClusters.targetClusterTemplate"
                    ] = target_template
                    logger.info(f"Setting target cluster template to: {target_template}")

                if not self.k8s_service.helm_install(
                    chart_path=self.ma_chart_path,
                    release_name=MA_RELEASE_NAME,
                    values=chart_values
                ):
                    raise HelmCommandFailed(
                        "Helm install of Migrations Assistant chart failed"
                    )

                # Force update cluster templates to ensure latest changes are used
                logger.info("Force updating cluster templates...")
                try:
                    # Use absolute path from repo root
                    repo_root = os.path.abspath(
                        os.path.join(os.path.dirname(__file__), "../../..")
                    )
                    template_path = os.path.join(
                        repo_root,
                        "TrafficCapture/dockerSolution/src/main/docker/"
                        "migrationConsole/workflows/templates/clusterTemplates.yaml"
                    )xisting template first to force recreation
                    subprocess.run(["kubectl", "delete", "workflowtemplate", "cluster-templates", "-n", "ma", "--ignore-not-found=true"], 
                                 check=True, capture_output=True)
                    
                    # Apply the updated template
                    subprocess.run(["kubectl", "apply", "-f", template_path, "-n", "ma"], 
                                 check=True, capture_output=True)
                    logger.info("Cluster templates force updated successfully")
                except subprocess.CalledProcessError as e:
                    logger.warning(f"Failed to update cluster templates: {e}")
                except Exception as e:
                    logger.warning(f"Error updating cluster templates: {e}")

                self.k8s_service.wait_for_all_healthy_pods()

                tests_passed = self.run_tests(source_version=source_version,
                                              target_version=target_version,
                                              keep_workflows=keep_workflows,
                                              reuse_clusters=reuse_clusters)

                if not tests_passed:
                    raise TestsFailed(f"Tests failed (or no tests executed) for migrations "
                                      f"from {source_version} to {target_version}.")
                else:
                    logger.info(f"Tests passed successfully for migrations "
                                f"from {source_version} to {target_version}.")
            except HelmCommandFailed as helmError:
                logger.error(f"Helm command failed with error: {helmError}. Testing may be incomplete")
            except TimeoutError as timeoutError:
                logger.error(f"Timeout error encountered: {timeoutError}. Testing may be incomplete")

            if not skip_delete:
                self.cleanup_deployment()

        logger.info("Test execution completed.")


def _parse_test_ids(test_ids_str: str) -> List[str]:
    # Split the string by commas and remove extra whitespace
    return [tid.strip() for tid in test_ids_str.split(",") if tid.strip()]


def _generate_unique_id() -> str:
    """Generate a human-readable unique ID with a timestamp and a 4-character random string."""
    timestamp = datetime.datetime.now().strftime("%Y%m%d%H%M%S")
    random_part = ''.join(random.choices(string.ascii_lowercase + string.digits, k=4))
    return f"{random_part}-{timestamp}"


def parse_version_string(version_str: str) -> tuple[str, str, str]:
    """Parse a string in format ES|OS_x.y and return the distinct pieces as (cluster_type, major, minor)"""
    try:
        cluster_type_part, version_part = version_str.split('_', 1)
        major_str, minor_str = version_part.split('.', 1)

        cluster_type = cluster_type_part.lower()
        major = str(int(major_str))

        try:
            minor = str(int(minor_str))
        except ValueError:
            minor = str(minor_str)

        return cluster_type, major, minor
    except (ValueError, AttributeError):
        raise ValueError(f"Invalid version string format: '{version_str}'")


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Process inputs for test automation runner"
    )
    parser.add_argument(
        "--source-version",
        choices=VALID_SOURCE_VERSIONS,
        default="ES_5.6",
        help=f"Source version to use. Must be one of: {', '.join(VALID_SOURCE_VERSIONS)}"
    )
    parser.add_argument(
        "--target-version",
        choices=VALID_TARGET_VERSIONS,
        default="OS_2.19",
        help=f"Target version to use. Must be one of: {', '.join(VALID_TARGET_VERSIONS)}"
    )
    parser.add_argument(
        "--skip-delete",
        action="store_true",
        help="If set, skip deletion operations."
    )
    parser.add_argument(
        "--delete-only",
        action="store_true",
        help="If set, only perform deletion operations."
    )
    parser.add_argument(
        "--delete-clusters-only",
        action="store_true",
        help="If set, only perform cluster deletion operations."
    )
    parser.add_argument(
        "--copy-logs-only",
        action="store_true",
        help="If set, only copy found argo workflow logs to the current directory."
    )
    parser.add_argument(
        '--unique-id',
        type=str,
        default=_generate_unique_id(),
        help="Provide a unique ID for labeling test resources, or generate one by default"
    )
    parser.add_argument(
        "--keep-workflows",
        action="store_true",
        help="If set, will not delete argo workflows created by integration tests"
    )
    parser.add_argument(
        "--developer-mode",
        action="store_true",
        help="If set, will enable the developer mode flag for the Migration Assistant helm chart"
    )
    parser.add_argument(
        "--reuse-clusters",
        action="store_true",
        help="If set, the integration tests will reuse existing clusters that match the naming pattern "
             "e.g. 'target-opensearch-2-19-*'. If a cluster does not exist the integration test will create it and "
             "leave it running once the test completes for other tests to use. The cleanup operation for this library "
             "will remove all source and target clusters that match this pattern as well."
    )
    parser.add_argument(
        "--dev",
        action="store_true",
        help="An aggregate flag to apply developer settings for "
             "testing [--skip-delete, --reuse-clusters, --keep-workflows, --developer-mode]"
    )
    parser.add_argument(
        "--test-ids",
        type=_parse_test_ids,
        default=[],
        help="Comma-separated list of test IDs to run (e.g. 0001,0003)"
    )
    return parser.parse_args()


def main() -> None:
    args = parse_args()
    k8s_service = K8sService()
    helm_k8s_base_path = "../../deployment/k8s"
    helm_charts_base_path = f"{helm_k8s_base_path}/charts"
    ma_chart_path = f"{helm_charts_base_path}/aggregates/migrationAssistantWithArgo"

    combinations = [(args.source_version, args.target_version)]
    test_runner = TestRunner(k8s_service=k8s_service,
                             unique_id=args.unique_id,
                             test_ids=args.test_ids,
                             ma_chart_path=ma_chart_path,
                             combinations=combinations)

    if args.delete_only:
        return test_runner.cleanup_deployment()
    if args.delete_clusters_only:
        return test_runner.cleanup_clusters()
    if args.copy_logs_only:
        return test_runner.copy_logs()
    skip_delete = args.skip_delete
    keep_workflows = args.keep_workflows
    developer_mode = args.developer_mode
    reuse_clusters = args.reuse_clusters
    if args.dev:
        skip_delete = True
        keep_workflows = True
        developer_mode = True
        reuse_clusters = True
    test_runner.run(skip_delete=skip_delete,
                    keep_workflows=keep_workflows,
                    developer_mode=developer_mode,
                    reuse_clusters=reuse_clusters)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        # Handle Ctrl+C cleanly too
        sys.exit(0)
    except Exception as e:
        logger.error(f"Fatal error: {e}")
        sys.exit(1)
